import numpy as np
import matplotlib.pyplot as plt

class Environment:
    """
    Initialize the environment. This is a 2D square of side length 1.0, centered at the origin.  
    The agent always starts at the center (0, 0).  
    A food source is placed on a circle of radius 0.5 at an angle you choose. 

    The environment is updated by inserting an action (0: left, 1: right, 2: up, 3: down).  
    The agent moves 0.1 units in the chosen direction, unless that would take it outside the square.
    The observation returned is the agent's position encoded by place cells.  
    The episode ends when the agent reaches the food (within 0.075 units). 

    The environment uses a grid of Gaussian place cells to encode positions.  
    Each center acts like a "receptive field" responding to agent location.

    Args:
        grid_size (int): Number of grid points per axis for the place-cell centers.
        sigma (float): Width of the Gaussian tuning curves for place cells.
        spatial_res (int | None): Resolution used by generic encoders if not specified.
        sigma_distribution (float | None): Spread in degrees for randomizing food angle.
    """
    def __init__(self, grid_size = 5, sigma = 0.2, spatial_res = None, sigma_distribution = None):

        self.spatial_res = spatial_res if spatial_res is not None else 5
        self.sigma_distribution = sigma_distribution if sigma_distribution is not None else 10
        self.agent_position = np.array([0, 0])  
        self.food_position = self._generate_food_position(0.0)
        self.square_size = 1.0
        self.grid_size = grid_size
        self.sigma = sigma
        self.grid_centers = self._generate_grid_centers()
        self.encoded_position = self.encode_position(self.agent_position)

    def _generate_grid_centers(self):
        """
        Lay down the centers of the place-cell grid.

        The grid covers roughly [-0.55, 0.55] in x and [-0.55, 0.5] in y.  
        Each center is used to compute Gaussian activations of the agent’s position.

        Returns:
            np.ndarray: Array of (x, y) coordinates for all place-cell centers.
        """
        x = np.linspace(-.55, .55, self.grid_size)
        y = np.linspace(-.55, .5, self.grid_size)
        grid_centers = np.array([(x_coord, y_coord) for x_coord in x for y_coord in y])
        return grid_centers

    def _generate_food_position(self, theta0=45):
        """
        Place the food at a fixed distance from the origin.

        The food is always 0.5 units away from the origin, positioned  
        at an angle `theta0` (in degrees) measured counter-clockwise from the x-axis.

        Args:
            theta0 (float): Food angle in degrees.

        Returns:
            tuple[float, float]: Coordinates (x, y) of the food.
        """
        theta = theta0 / 180 * np.pi
        return .5*np.cos(theta),.5*np.sin(theta)

    def reset(self, theta0=45):
        """
        Reset the environment to the start of a new episode.

       This means that the agent is placed at the origin (0, 0), and the food is placed at the specified angle.

        Args:
            theta0 (float): Food angle in degrees.
        """
        self.agent_position = np.array([0., 0.])  
        self.encoded_position = self.encode_position(self.agent_position)
        self.food_position = np.round(self._generate_food_position(theta0), decimals=1)  

    def reset_inner(self):
        """
        Reset only the agent’s position to the origin (0, 0).
        """
        self.agent_position = np.array([0., 0.])  
        self.encoded_position = self.encode_position(self.agent_position)

    def encode_position(self, position):
        """
        Turn a 2D position into place-cell activity.

        Each place cell has a Gaussian receptive field centered on a grid point among the ones generated by `_generate_grid_centers()` at __init__ time. 
        The closer the agent is to that center, the higher the activation. This is a simple yet effective way to augment the dimensionality of the input space.

        Args:
            position (tuple | np.ndarray): (x, y) coordinates.

        Returns:
            np.ndarray: Activation values, one per place cell.
        """
        x, y = position
        activation_levels = np.exp(-((x - self.grid_centers[:, 0])**2 + (y - self.grid_centers[:, 1])**2) / (2 * self.sigma**2))
        return activation_levels

    def encode(self, x, angle=False, res=None):
        """
        Generic encoder for scalar values, takes one or more values and encodes them using Gaussian basis functions, according
        to the specified resolution. Since the angles are provided in degrees, but degrees are huge numbers, in degree mode
        the input is first converted to radians.

        Args:
            x (float | list | np.ndarray): Input value(s) to encode.
            angle (bool): If True, input is treated as an angle in radians and normalized accordingly.
            res (int | None): Number of Gaussian basis functions to use. If None, defaults to 10.
        Returns:
            np.ndarray: Encoded representation of the input value(s).
        """
        if res is None: res = 10
        if angle:
            x = x / np.pi 
        x = np.array(x).T
        mu_x = np.linspace(-1., 1., num=res).T
        s_x = np.diff((-1., 1.), axis=0).T / (res)
        enc_x = np.exp(-1 * ((x.reshape(-1, 1) - mu_x) / s_x)**2).T
        return enc_x
    
    def encode_entropy(self, x, res=None):
        """
        Same role as encode(), but for entropy values, which are always positive and in the range [0, 2], so the gaussians centers are shifted
        accordingly. Being this a low level function as encode(), we don't want to include too many ifs and checks.

        Args:
            x (float | list | np.ndarray): Input value(s) to encode.
            res (int | None): Number of Gaussian basis functions to use. If None, defaults to 10.
        Returns:
            np.ndarray: Encoded representation of the input value(s).
        """
        if res is None: res = 10
        x = np.array(x).T
        mu_x = np.linspace(0., 2., num=res).T
        s_x = np.diff((0., 2.), axis=0).T / (res)
        enc_x = np.exp(-1 * ((x.reshape(-1, 1) - mu_x) / s_x)**2).T
        return enc_x

    def step(self, action):
        """
        Update the environment based on the agent's action. The action is an integer:
        0: move left, 1: move right, 2: move up, 3: move down. The agent moves 0.1 units in the chosen direction,
        unless that would take it outside the square. The function returns a reward and a done flag in case the food is reached.
        Args:
            action (int): Action to take (0: left, 1: right, 2: up, 3: down).
        Returns:
            tuple: (reward (float), done (bool))
        """
        new_position = self.agent_position.copy()
        if action == 0:
            new_position[0] -= 0.1
        elif action == 1:
            new_position[0] += 0.1
        elif action == 2:
            new_position[1] += 0.1
        elif action == 3:
            new_position[1] -= 0.1

        distance_to_food = np.linalg.norm(new_position - self.food_position)
        reward = 0
        done = False
        
        if distance_to_food < 0.15:
            reward += 1
        if distance_to_food < 0.075:
            reward += 0.5
            done = True

        self.agent_position = np.clip(new_position, -self.square_size/2, self.square_size/2)
        self.encoded_position = self.encode_position(self.agent_position)
        
        return reward, done

    def render(self, ax=None, title='Agent Environment', lims=0.75):
        """
        Render the current state of the environment into the given Axes.

        Args:
            ax (matplotlib.axes.Axes, optional): If provided, draw into this Axes.
            lims (float): Limits for the plot axes.

        Returns:
            matplotlib.axes.Axes: The Axes object containing the plot.
        """
        if ax is None:
            fig, ax = plt.subplots(figsize=(5, 5))
        ax.set_xlim(-lims, lims)
        ax.set_ylim(-lims, lims)
        ax.plot(self.agent_position[0],
                self.agent_position[1],
                'bo',
                markersize=10,
                label='Agent')
        ax.plot(self.food_position[0],
                self.food_position[1],
                'rx',
                markersize=10,
                label='Food')
        ax.legend()
        ax.set_title(title)
        ax.grid(True)
        return ax


def testing_environment():
    """Simple tests and visualizations for the Environment class."""

    env = Environment(grid_size=10, sigma=0.2)
    env.reset()
    print("Food Position:", env.food_position)
    print("Agent Position:", env.agent_position)

    encoded_position = env.encode_position((0.1, 0.2))
    print("Encoded Position:", encoded_position)
    print("Encoded Position Shape:", encoded_position.shape)
    print("Reward Encoded:", env.encode(0, res=5))

    reward, done = env.step(1)
    print("Reward:", reward, "Done:", done)

    fig, ax = plt.subplots(figsize=(6, 6))
    ax.set_xlim(-0.75, 0.75)
    ax.set_ylim(-0.75, 0.75)
    ax.grid(True)
    ax.set_title('Agent Environment - All Resets')
    ax.plot(env.agent_position[0], env.agent_position[1], 'bo', markersize=10, label='Agent (start)')

    n_resets = 8
    n_angle = 0

    for n in range(n_resets):
        theta0 = 45 * n_angle
        n_angle += 1
        env.reset(theta0=theta0)
        ax.plot(env.food_position[0], env.food_position[1], 'rx', markersize=8)

    ax.legend(["Agent (start)", "Food positions"])
    plt.show()

if __name__ == "__main__":
    testing_environment()